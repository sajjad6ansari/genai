{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9FRZAfU/cxYXVlV3gsIxH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajjad6ansari/genai/blob/main/ModelsExamples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalisation example"
      ],
      "metadata": {
        "id": "DdbJgt4jrxmI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAuvaklCrqDL",
        "outputId": "ee89371f-9f0d-419b-c93d-43bf5e196600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data: [  10   20   30   40   50 1000]\n",
            "Min-Max Scaled: [0.         0.01010101 0.02020202 0.03030303 0.04040404 1.        ]\n",
            "Z-Score Scaled: [-0.50221883 -0.47457376 -0.44692869 -0.41928361 -0.39163854  2.23464343]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#sample data\n",
        "data = np.array([10, 20, 30, 40, 50, 1000]) #1000 is outlier\n",
        "\n",
        "#Min-Max scaling : scales values b/w 0 and 1\n",
        "def min_max_scaling(data):\n",
        "  min_val = np.min(data)\n",
        "  max_val = np.max(data)\n",
        "  return (data - min_val) / (max_val - min_val)\n",
        "\n",
        "#Z-score  standardization : Mean = 0, Std Deviation = 1\n",
        "def z_score_standardization(data):\n",
        "  mean = np.mean(data)\n",
        "  std_dev = np.std(data)\n",
        "  return (data - mean) / std_dev\n",
        "\n",
        "# Apply normalization techniques\n",
        "min_max_scaled = min_max_scaling(data)\n",
        "z_score_scaled = z_score_standardization(data)\n",
        "\n",
        "#print results\n",
        "print(\"Original Data:\", data)\n",
        "print(\"Min-Max Scaled:\", min_max_scaled)\n",
        "print(\"Z-Score Scaled:\", z_score_scaled)# the +ve value is outlier\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Example 1 : MNIST Handwritten Digits Classifcation**"
      ],
      "metadata": {
        "id": "8GdmVdWGElLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Dense Layers always except a 1D i/p, so whenever the preceding layer produces multi-dimentional o/p,\n",
        "# we must flatten it to 1D before passing it to the Dense layer\n",
        "\n",
        "#if the i/p to a dense layer is not already 1D, use flatten to convert it to 1D\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "#print(predictions)\n",
        "#print('predictions shape : ', predictions.shape)\n",
        "\n",
        "plt.imshow(x_test[7],cmap='grey')\n",
        "plt.title(f\"True Label : {y_test[7]}, Predicted : {np.argmax(predictions[7])}\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "kAuh1n5HE1pU",
        "outputId": "a8e9cd1d-3ac4-45dc-e0fd-9f7e939ac6e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.4390\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1249\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0780\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0593\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0434\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0846\n",
            "Test accuracy: 97.69%\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2 - House Price Prediction (Regression)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d0txsVDAGyUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Synthetic Data**"
      ],
      "metadata": {
        "id": "4c8fhfZqHhLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - House price prediction (Regression)  with synthetic data\n",
        "# Predict  house proces based on 10 numerical features\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic dataset (1000 samples, 10 features)\n",
        "np.random.seed(42)\n",
        "x_train = np.random.rand(1000, 10)\n",
        "y_train = np.random.rand(1000) * 50000   #House prices b/w 0-500k\n",
        "\n",
        "x_test = np.random.rand(200, 10)\n",
        "y_test = np.random.rand(200) * 50000\n",
        "\n",
        "# Build Model\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1) # single o/p for regression\n",
        "])\n",
        "\n",
        "#compile model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "#Train Model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "#Evaluate mode\n",
        "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
        "print(f'Test MAE: ${test_mae:.2f}')\n",
        "\n",
        "#make predictions\n",
        "sample_input = np.random.rand(1, 10)\n",
        "predicted_price = model.predict(sample_input)\n",
        "print(f'Predicted House Price: ${predicted_price[0][0]:.2f}')\n",
        "\n",
        "# MAE is around 243k-245k, which means on average, the predictions are off by near half of the actual house price\n",
        "# This is very bad bcz an error of 243k  in a price of 500k  means  the model is almost random\n",
        "# The dataset is  completely random, meaning there is no real pattern for the model to learn\n",
        "# The model is guessing the house price randomly, which is why MAE is large\n",
        "# In short, bad model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3jRhKsf_G7nj",
        "outputId": "e322063c-0187-4727-c581-db06c707a9fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 828341760.0000 - mae: 25204.8457\n",
            "Epoch 2/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 872310272.0000 - mae: 25705.6133\n",
            "Epoch 3/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 848857088.0000 - mae: 25251.0000\n",
            "Epoch 4/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 833355456.0000 - mae: 25023.4609\n",
            "Epoch 5/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 879858944.0000 - mae: 25842.8398\n",
            "Epoch 6/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 840610112.0000 - mae: 25265.6973\n",
            "Epoch 7/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 859388672.0000 - mae: 25423.2070\n",
            "Epoch 8/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 812064128.0000 - mae: 24632.3125\n",
            "Epoch 9/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 840054528.0000 - mae: 25341.9570\n",
            "Epoch 10/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 821890944.0000 - mae: 24878.9141\n",
            "Epoch 11/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 775561536.0000 - mae: 23807.1309\n",
            "Epoch 12/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 788306304.0000 - mae: 24295.2617\n",
            "Epoch 13/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 741100544.0000 - mae: 23285.4707\n",
            "Epoch 14/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 717500032.0000 - mae: 22912.8301\n",
            "Epoch 15/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 687291968.0000 - mae: 22279.8438\n",
            "Epoch 16/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 659961280.0000 - mae: 21663.8262\n",
            "Epoch 17/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 618774656.0000 - mae: 20858.3457\n",
            "Epoch 18/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 597223872.0000 - mae: 20466.8477\n",
            "Epoch 19/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 545047680.0000 - mae: 19435.8984\n",
            "Epoch 20/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 523888480.0000 - mae: 18975.9414\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 519343040.0000 - mae: 18455.7441  \n",
            "Test MAE: $17562.18\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Predicted House Price: $9723.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Synthetic Data and Normalization**"
      ],
      "metadata": {
        "id": "VIVzKV_IkGFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - House Price Prediction (Regression) with synthetic dataset and Normalization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic  dataset (1000 samples, 10 features) in [0,1] ranges\n",
        "np.random.seed(42)\n",
        "x_train = np.random.rand(1000, 10)\n",
        "y_train = np.random.rand(1000)   #House prices b/w 0-1\n",
        "\n",
        "x_test = np.random.rand(200, 10)\n",
        "y_test = np.random.rand(200) # Targets ranges in 0-1\n",
        "\n",
        "# Build Model\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1) # single o/p for regression\n",
        "])\n",
        "\n",
        "#compile model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "#Train Model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "#Evaluate mode\n",
        "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
        "print(f'Test MAE: ${test_mae:.2f}')\n",
        "\n",
        "#make predictions\n",
        "sample_input = np.random.rand(1, 10)\n",
        "predicted_price = model.predict(sample_input)\n",
        "print(f'Predicted House Price: ${predicted_price[0][0]:.4f}')\n",
        "#this is also bad model  as we are still training  in random values (just the values the normalised)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l0ZKe1hEm6Cd",
        "outputId": "47da3891-2b91-4410-d35f-26d3fb1d0cea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2688 - mae: 0.4342\n",
            "Epoch 2/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0849 - mae: 0.2439\n",
            "Epoch 3/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0858 - mae: 0.2504\n",
            "Epoch 4/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0825 - mae: 0.2440\n",
            "Epoch 5/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0808 - mae: 0.2414\n",
            "Epoch 6/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0811 - mae: 0.2436\n",
            "Epoch 7/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0827 - mae: 0.2483\n",
            "Epoch 8/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0807 - mae: 0.2420\n",
            "Epoch 9/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0865 - mae: 0.2541\n",
            "Epoch 10/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0831 - mae: 0.2457\n",
            "Epoch 11/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0816 - mae: 0.2465\n",
            "Epoch 12/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0809 - mae: 0.2445\n",
            "Epoch 13/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0819 - mae: 0.2445\n",
            "Epoch 14/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0778 - mae: 0.2383\n",
            "Epoch 15/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0813 - mae: 0.2473\n",
            "Epoch 16/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0775 - mae: 0.2381\n",
            "Epoch 17/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0754 - mae: 0.2343\n",
            "Epoch 18/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0780 - mae: 0.2399\n",
            "Epoch 19/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0787 - mae: 0.2399\n",
            "Epoch 20/20\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0761 - mae: 0.2341\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1027 - mae: 0.2741  \n",
            "Test MAE: $0.27\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Predicted House Price: $0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset from scikit-learn**"
      ],
      "metadata": {
        "id": "pnzXVe9RoIJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2 - House Price Prediction (Regression) with Dataset from scikit-learn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "#Load california housing dataset\n",
        "data = fetch_california_housing()\n",
        "x, y = data.data, data.target   #Features  and target (mediam house  value in 100,000s )\n",
        "\n",
        "print(f'Target value Range (in 100,00s): Min = {y.min():.2f}, Max = {y.max():.2f}, Mean = {y.mean():.2f}')\n",
        "\n",
        "#Split the data  into train and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Normalize the features for better  training stability - Z_Score_Standardization/ Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train) #compute mean  and std from  trainn=ing data then scale\n",
        "x_test = scaler.transform(x_test) # use the same scaling parameter to transform test data\n",
        "\n",
        "\n",
        "#we use same mean and std deviation  (computed from x_train ) to scale x_test\n",
        "# This ensures the both the training and the test data follow the  same distribution\n",
        "\n",
        "# if we include x_test while computing mean and std. deviation. the model gets the information from the test data before training\n",
        "# This is called data leakage which can lead to unrealisticlly good performance on test data and poor on generalization to the new data\n",
        "# Test Data should only  be used to for evaluation after the model is trained\n",
        "\n",
        "# In real-world  applications, new data arrives after training, we do not  get to compute the mean and std  deviation for each new data point\n",
        "# The model should be able to handle the unseen data  using the same scaling applied during the training\n",
        "\n",
        "# Build Model\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)), #i/p features from dataset\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1) # single o/p for regression\n",
        "])\n",
        "\n",
        "#compile model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "#Train Model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "#Evaluate mode\n",
        "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
        "print(f'Test MAE: ${test_mae * 100000:.2f}') #convert to actual dollars\n",
        "\n",
        "#make predictions\n",
        "sample_input = np.expand_dims(x_test[0], axis=0) #Take one test sample\n",
        "predicted_price = model.predict(sample_input)\n",
        "print(f'Predicted House Price: ${predicted_price[0][0] * 100000:.2f}') #convert to actual dollars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JoEvTpc1nr7K",
        "outputId": "a8bdd4e8-2384-468e-c246-c0abacf00e82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target value Range (in 100,00s): Min = 0.15, Max = 5.00, Mean = 2.07\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 1.5210 - mae: 0.8131\n",
            "Epoch 2/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4268 - mae: 0.4669\n",
            "Epoch 3/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3825 - mae: 0.4368\n",
            "Epoch 4/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3769 - mae: 0.4217\n",
            "Epoch 5/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3559 - mae: 0.4137\n",
            "Epoch 6/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3337 - mae: 0.4037\n",
            "Epoch 7/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3171 - mae: 0.3933\n",
            "Epoch 8/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3031 - mae: 0.3862\n",
            "Epoch 9/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3157 - mae: 0.3887\n",
            "Epoch 10/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2932 - mae: 0.3777\n",
            "Epoch 11/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2992 - mae: 0.3810\n",
            "Epoch 12/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2839 - mae: 0.3731\n",
            "Epoch 13/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2852 - mae: 0.3698\n",
            "Epoch 14/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3092 - mae: 0.3719\n",
            "Epoch 15/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2872 - mae: 0.3718\n",
            "Epoch 16/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2808 - mae: 0.3630\n",
            "Epoch 17/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2919 - mae: 0.3745\n",
            "Epoch 18/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2819 - mae: 0.3635\n",
            "Epoch 19/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2694 - mae: 0.3603\n",
            "Epoch 20/20\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2683 - mae: 0.3583\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2791 - mae: 0.3712\n",
            "Test MAE: $37589.08\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Predicted House Price: $52833.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3 - Sentiment Analysis (Binary Classification)**"
      ],
      "metadata": {
        "id": "7GTQhezNCnRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Without Embedding layers**"
      ],
      "metadata": {
        "id": "5eXz487QC6kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exmample 3 - Sentiment Analysis (Binary Classification) Without Embedding layers\n",
        "# classify whether a review is +ve or not\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import numpy as np\n",
        "\n",
        "# Load IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n",
        "\n",
        "#IMDB reviews  have different lenghts, but  dense expects a fixed length og neurons\n",
        "# we are ensuring that every i/p is exactly 200 words\n",
        "\n",
        "# Pad sequences to ensure fixed length i/p\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "\n",
        "#Build model using only Dense layers\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(200,)), #convert 2D sequence to 1D\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') #Binary classification\n",
        "])\n",
        "\n",
        "#compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Train Model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=512)\n",
        "\n",
        "#Evaluate mode\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%') #convert to actual dollars\n",
        "\n",
        "#make predictions\n",
        "predicted_sentiment = model.predict(x_test[0:1])\n",
        "\n",
        "#print(f'x_test[0:1] = {x_test[0:1]}')\n",
        "print(f'Predicted Sentiment:', \"Positive\" if predicted_sentiment[0][0] > 0.5 else \"Negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mUIZ6C_PC-87",
        "outputId": "2e7a3f54-e428-4323-aec6-202ca91d7f51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5038 - loss: 28.2933\n",
            "Epoch 2/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5306 - loss: 7.9042\n",
            "Epoch 3/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5440 - loss: 4.3063\n",
            "Epoch 4/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5500 - loss: 2.6788\n",
            "Epoch 5/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5491 - loss: 1.5678\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5114 - loss: 1.3053\n",
            "Test accuracy: 50.76%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "x_test[0:1] = [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   1 591 202  14  31   6 717  10  10   2   2   5\n",
            "    4 360   7   4 177   2 394 354   4 123   9   2   2   2  10  10  13  92\n",
            "  124  89 488   2 100  28   2  14  31  23  27   2  29 220 468   8 124  14\n",
            "  286 170   8 157  46   5  27 239  16 179   2  38  32  25   2 451 202  14\n",
            "    6 717]]\n",
            "Predicted Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **With Embedding layer**\n",
        "Embedding layer  *transforms  interger word indices into dense vector representation*\n",
        "\n"
      ],
      "metadata": {
        "id": "48g7BMFqIBDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exmample 3 - Sentiment Analysis (Binary Classification) With Embedding layers\n",
        "# classify whether a review is +ve or not\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "# Load IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n",
        "\n",
        "#IMDB reviews  have different lenghts, but  dense expects a fixed length og neurons\n",
        "# we are ensuring that every i/p is exactly 200 words\n",
        "\n",
        "# Pad sequences to ensure fixed length i/p\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n",
        "\n",
        "#Build model using only Dense layers with an Embedding Layer\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(input_dim=10000, output_dim=128, input_length=200), #convert words indices into vectors\n",
        "    layers.Flatten(), #flatten embedding into a 1D  vector\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') #Binary classification\n",
        "])\n",
        "\n",
        "#compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Train Model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=512)\n",
        "\n",
        "#Evaluate mode\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%') #convert to actual dollars\n",
        "\n",
        "#make predictions\n",
        "predicted_sentiment = model.predict(x_test[0:1])\n",
        "\n",
        "#print(f'x_test[0:1] = {x_test[0:1]}')\n",
        "print(f'Predicted Sentiment:', \"Positive\" if predicted_sentiment[0][0] > 0.5 else \"Negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Azq9M1aIIkFX",
        "outputId": "b2df2aa0-c957-432b-abcf-8c02c054eea8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 374ms/step - accuracy: 0.5897 - loss: 0.6490\n",
            "Epoch 2/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 399ms/step - accuracy: 0.9244 - loss: 0.2050\n",
            "Epoch 3/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 376ms/step - accuracy: 0.9922 - loss: 0.0385\n",
            "Epoch 4/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 408ms/step - accuracy: 0.9992 - loss: 0.0052\n",
            "Epoch 5/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 380ms/step - accuracy: 0.9999 - loss: 0.0020\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.8515 - loss: 0.5660\n",
            "Test accuracy: 85.25%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
            "Predicted Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Breast Cancer Prediction (Binary Classification)**"
      ],
      "metadata": {
        "id": "gHiFZ1LBOIE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Breast Cancer dataset from scikit-learn contains 569 samples with 30 numerical features extracted\n",
        "# from digitalised images of breast mass tumors, The goal is to tumors as malignant(1) or benign(0)\n",
        "# based on these feaures , the dataset as originally curated from Winconsin Diagonistic Breast Cancer (WDBC)\n",
        "# dataset and is commonly used in bainary classification tasks in ML\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import models, layers\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "#Load breast_cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target   #Features  and labels\n",
        "\n",
        "#Split the data  into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train) #compute mean  and std from  trainn=ing data then scale\n",
        "X_test = scaler.transform(X_test) # use the same scaling parameter to transform test data\n",
        "\n",
        "# Build Model\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)), #i/p features from dataset\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1) #Binary Classification\n",
        "])\n",
        "\n",
        "#compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Train Model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "#Evaluate model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGE-VVlpK3A4",
        "outputId": "1fbb2220-f5ae-4f74-aba2-290a3ff60efd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5240 - loss: 2.8061 - val_accuracy: 0.9386 - val_loss: 0.1369\n",
            "Epoch 2/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8946 - loss: 0.8330 - val_accuracy: 0.9737 - val_loss: 0.0607\n",
            "Epoch 3/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9398 - loss: 0.2773 - val_accuracy: 0.9912 - val_loss: 0.0519\n",
            "Epoch 4/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9505 - loss: 0.2995 - val_accuracy: 0.9912 - val_loss: 0.0520\n",
            "Epoch 5/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9473 - loss: 0.2244 - val_accuracy: 0.9912 - val_loss: 0.0521\n",
            "Epoch 6/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9584 - loss: 0.3140 - val_accuracy: 0.9825 - val_loss: 0.0531\n",
            "Epoch 7/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9663 - loss: 0.3080 - val_accuracy: 0.9825 - val_loss: 0.0546\n",
            "Epoch 8/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9611 - loss: 0.3595 - val_accuracy: 0.9825 - val_loss: 0.0571\n",
            "Epoch 9/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9767 - loss: 0.1627 - val_accuracy: 0.9825 - val_loss: 0.0611\n",
            "Epoch 10/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9742 - loss: 0.3191 - val_accuracy: 0.9649 - val_loss: 0.0629\n",
            "Epoch 11/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9731 - loss: 0.2881 - val_accuracy: 0.9825 - val_loss: 0.1730\n",
            "Epoch 12/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9788 - loss: 0.3066 - val_accuracy: 0.9649 - val_loss: 0.1740\n",
            "Epoch 13/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9771 - loss: 0.2746 - val_accuracy: 0.9737 - val_loss: 0.1728\n",
            "Epoch 14/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9728 - loss: 0.2988 - val_accuracy: 0.9737 - val_loss: 0.1721\n",
            "Epoch 15/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.2507 - val_accuracy: 0.9649 - val_loss: 0.1026\n",
            "Epoch 16/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.1635 - val_accuracy: 0.9649 - val_loss: 0.3308\n",
            "Epoch 17/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9718 - loss: 0.1864 - val_accuracy: 0.9649 - val_loss: 0.4387\n",
            "Epoch 18/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9809 - loss: 0.1982 - val_accuracy: 0.9649 - val_loss: 0.4390\n",
            "Epoch 19/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.1974 - val_accuracy: 0.9649 - val_loss: 0.4400\n",
            "Epoch 20/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9800 - loss: 0.2023 - val_accuracy: 0.9649 - val_loss: 0.4405\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9558 - loss: 0.6343 \n",
            "Test accuracy: 96.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBUrdnLxTpUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}